---
title: "Brooklyn Housing - Modelling Codebase"
author: "Kshitij Mittal"
date: "2022-12-18"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Calling Relevant Packages
```{r packages}
library(dplyr)
library(stringr)
library(readr)
library(relaimpo)
library(ggplot2)
library(lmtest)
```

# 1.1 Bring the data into R 

```{r data}
dat_2016 = read.csv('/Users/kshitijmittal/Documents/UChicago Acad/01 Quarter 1/01 Stat Analysis/99 Final Project Part 1/2016_brooklyn.csv')
dat_2017 = read.csv('/Users/kshitijmittal/Documents/UChicago Acad/01 Quarter 1/01 Stat Analysis/99 Final Project Part 1/2017_brooklyn.csv')
dat_2018 = read.csv('/Users/kshitijmittal/Documents/UChicago Acad/01 Quarter 1/01 Stat Analysis/99 Final Project Part 1/2018_brooklyn.csv')
dat_2019 = read.csv('/Users/kshitijmittal/Documents/UChicago Acad/01 Quarter 1/01 Stat Analysis/99 Final Project Part 1/2019_brooklyn.csv')
dat_2020 = read.csv('/Users/kshitijmittal/Documents/UChicago Acad/01 Quarter 1/01 Stat Analysis/99 Final Project Part 1/2020_brooklyn.csv')

colnames(dat_2016) = c('borough','neighborhood','bldclasscat','taxclasscurr','block','lot','easement','bldclasscurr','address','aptnum','zip','resunits','comunits','totunits','landsqft','grosssqft','yrbuilt','taxclasssale','bldclasssale','price','date') 
colnames(dat_2017) = c('borough','neighborhood','bldclasscat','taxclasscurr','block','lot','easement','bldclasscurr','address','aptnum','zip','resunits','comunits','totunits','landsqft','grosssqft','yrbuilt','taxclasssale','bldclasssale','price','date') 
colnames(dat_2018) = c('borough','neighborhood','bldclasscat','taxclasscurr','block','lot','easement','bldclasscurr','address','aptnum','zip','resunits','comunits','totunits','landsqft','grosssqft','yrbuilt','taxclasssale','bldclasssale','price','date') 
colnames(dat_2019) = c('borough','neighborhood','bldclasscat','taxclasscurr','block','lot','easement','bldclasscurr','address','aptnum','zip','resunits','comunits','totunits','landsqft','grosssqft','yrbuilt','taxclasssale','bldclasssale','price','date') 
colnames(dat_2020) = c('borough','neighborhood','bldclasscat','taxclasscurr','block','lot','easement','bldclasscurr','address','aptnum','zip','resunits','comunits','totunits','landsqft','grosssqft','yrbuilt','taxclasssale','bldclasssale','price','date') 
```

#  1.2 Join the data and make it usable for analysis 

```{r data_cleaning}
dat_2016 = dat_2016[5:dim(dat_2016)[1],]  #Removing top 4 blank/non-data rows
dat_2017 = dat_2017[5:dim(dat_2017)[1],]  #Removing top 4 blank/non-data rows
dat_2018 = dat_2018[5:dim(dat_2018)[1],]  #Removing top 4 blank/non-data rows
dat_2019 = dat_2019[5:dim(dat_2019)[1],]  #Removing top 4 blank/non-data rows
dat_2020 = dat_2020[8:dim(dat_2020)[1],]  #Removing top 7 blank/non-data rows

# Removing all blank rows from the datasets
dat_2016 = dat_2016[!apply(dat_2016 == "", 1, all),]
dat_2017 = dat_2017[!apply(dat_2017 == "", 1, all),]
dat_2018 = dat_2018[!apply(dat_2018 == "", 1, all),]
dat_2019 = dat_2019[!apply(dat_2019 == "", 1, all),]
dat_2020 = dat_2020[!apply(dat_2020 == "", 1, all),]

# Creating different vectors for columns as per data types
cols.num=c("borough","taxclasscurr","block","lot","zip","resunits","comunits","totunits","yrbuilt","taxclasssale","aptnum")
cols.num2=c("landsqft","grosssqft","price")
cols.str=c("neighborhood","bldclasscat","easement","bldclasscurr","address","bldclasssale")

#Starting off with cleaning the 2016 data
dat_2016[cols.num]=sapply(dat_2016[cols.num],as.numeric) #Converting char data type to numeric
dat_2016[cols.num2]=sapply(dat_2016[cols.num2],parse_number) #Extracting numbers out of character data types with special characters
dat_2016[cols.str]=sapply(dat_2016[cols.str],str_trim) # Removing leading and trailing whitespaces from characters
dat_2016[cols.str]=sapply(dat_2016[cols.str],str_squish) # Removing middle whitespaces from characters
dat_2016$date=as.Date(dat_2016$date,"%m/%d/%Y") #Parsing date in an R friendly format

#Converting any blank values to 0 for this particular data set
dat_2016$price[is.na(dat_2016$price)]=0
dat_2016$comunits[is.na(dat_2016$comunits)]=0
dat_2016$resunits[is.na(dat_2016$resunits)]=0
dat_2016$totunits[is.na(dat_2016$totunits)]=0

#Repeating the above 5 types for 2017 data 
dat_2017[cols.num]=sapply(dat_2017[cols.num],as.numeric)
dat_2017[cols.num2]=sapply(dat_2017[cols.num2],parse_number)
dat_2017[cols.str]=sapply(dat_2017[cols.str],str_trim)
dat_2017[cols.str]=sapply(dat_2017[cols.str],str_squish)
dat_2017$date=as.Date(dat_2017$date,"%m/%d/%y")

#Repeating the above 5 types for 2018 data 
dat_2018[cols.num]=sapply(dat_2018[cols.num],as.numeric)
dat_2018[cols.num2]=sapply(dat_2018[cols.num2],parse_number)
dat_2018[cols.str]=sapply(dat_2018[cols.str],str_trim)
dat_2018[cols.str]=sapply(dat_2018[cols.str],str_squish)
dat_2018$date=as.Date(dat_2018$date,"%m/%d/%y")

#Repeating the above 5 types for 2019 data 
dat_2019[cols.num]=sapply(dat_2019[cols.num],as.numeric)
dat_2019[cols.num2]=sapply(dat_2019[cols.num2],parse_number)
dat_2019[cols.str]=sapply(dat_2019[cols.str],str_trim)
dat_2019[cols.str]=sapply(dat_2019[cols.str],str_squish)
dat_2019$date=as.Date(dat_2019$date,"%m/%d/%y")

#Repeating the above 5 types for 2019 data 
dat_2020[cols.num]=sapply(dat_2020[cols.num],as.numeric)
dat_2020[cols.num2]=sapply(dat_2020[cols.num2],parse_number)
dat_2020[cols.str]=sapply(dat_2020[cols.str],str_trim)
dat_2020[cols.str]=sapply(dat_2020[cols.str],str_squish)
dat_2020$date=as.Date(dat_2020$date,"%m/%d/%y")

#Ensuring all data types are consistent before joining
str(dat_2016)
str(dat_2017)
str(dat_2018)
str(dat_2019)
str(dat_2020)

```

```{r joining}
data_comb = rbind(dat_2016, dat_2017, dat_2018, dat_2019, dat_2020)
head(data_comb)
tail(data_comb)
dim(data_comb)
dim(dat_2016)[1] + dim(dat_2017)[1] + dim(dat_2018)[1] + dim(dat_2019)[1] + dim(dat_2020)[1] 
```

# 2.1 Exploratory data analysis 

```{r filtering}
# For the purposes of this analysis, we will only consider purchases
# of single-family residences and single-unit apartments or 
# condos.  

# Restrict the data to purchases where the building class at the time 
# of sale starts with ‘A’ or ‘R’ and 
index1 = with(data_comb, grepl("^A",bldclasssale))
index2 = with(data_comb, grepl("^R",bldclasssale))
data_comb1 = data_comb[index1|index2,]
unique(data_comb1$bldclasssale)

# The number of total units and the number of residential units are both 1.  
data_comb2 = data_comb1[data_comb1$totunits==1 & data_comb1$resunits==1,]
data_comb2 = data_comb2[!is.na(data_comb2$totunits),]
data_comb2 = data_comb2[!is.na(data_comb2$resunits),]

# Additionally restrict the data to observations where gross square footage is 
# more than 0 
data_comb3 = data_comb2[data_comb2$grosssqft>0,]
data_comb3 = data_comb3[!is.na(data_comb3$grosssqft),]

#Sale price is non-missing
data_comb4 = data_comb3[data_comb3$price>10,]
data_comb4 = data_comb4[!is.na(data_comb4$price),]

```

# Step 2: EDA and feature engineering 

```{r EDA}
# Our goal will be to use linear regression to explain Brooklyn housing prices 
# within the 2016-2020 window.  We will make predictions for the 
# sale prices within this dataset, and extract most explanatory power out of our variables.

# Consider price as a potential response variable. Examining how it is 
# distributed, and how it associates with the other variables in our data.  

data_mod = data_comb4
ggplot(data_mod[data_mod$price<5000000,], aes(x=price)) + geom_histogram(bins = 100) + ggtitle("Spread of Selling Price")
quantile(data_mod$price, probs = seq(.01, 1, by = .01))

ggplot(data_mod, aes(date, price)) + geom_point()
ggplot(data_mod, aes(yrbuilt, price)) + geom_point()
ggplot(data_mod, aes(grosssqft, price)) + geom_point()
ggplot(data_mod, aes(landsqft, price)) + geom_point()
ggplot(data_mod, aes(zip, price)) + geom_point()
ggplot(data_mod, aes(neighborhood, price)) + geom_point()

#Analyzing prices by neighbourhoods
neigh_price=data.frame(aggregate(data_mod$price, list(data_mod$neighborhood), FUN=mean))
neigh_price = neigh_price %>% arrange(x)
ggplot(neigh_price, aes(x=reorder(factor(Group.1),x), y=x)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

#Analyzing prices by zipcodes
zip_price=data.frame(aggregate(data_mod$price, list(data_mod$zip), FUN=mean))
zip_price = zip_price %>% arrange(x)
ggplot(zip_price, aes(x=reorder(factor(Group.1),x), y=x)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```


# 2.2 Pre-modeling and feature engineering 

```{r Zipcode}
# Making a new categorical variable for zipcodes by location - obtained from 
# New York City resources
Central = c(11213, 11216, 11225, 11233, 11226, 11218)
Eastern = c(11212, 11236, 11207, 11208, 11239, 11203)
Northern = c(11206, 11221, 11237, 11222, 11211, 11249)
Northwestern = c(11201, 11217, 11238, 11205, 11251, 11231, 11215)
Southern = c(11234, 11224, 11229, 11235, 11210, 11230, 11223)
Southwestern = c(11209, 11220, 11204, 11214, 11219, 11228, 11232)

data_mod$locality = as.factor(ifelse(data_mod$zip %in% Central, 'Central',
                                     ifelse(data_mod$zip %in% Eastern, 'Eastern',
                                            ifelse(data_mod$zip %in% Northern, 'Northern',
                                                   ifelse(data_mod$zip %in% Northwestern, 'Northwestern',
                                                          ifelse(data_mod$zip %in% Southern, 'Southern',
                                                                 ifelse(data_mod$zip %in% Southwestern, 'Southwestern',"")))))))

local_price=data.frame(aggregate(data_mod$price, list(data_mod$locality), FUN=mean))
ggplot(local_price, aes(x=reorder(factor(Group.1),x), y=x)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

```{r Quarter}
# Making a quarter variable for modelling

data_mod$quarter = as.factor(ifelse(data_mod$date >= "2016-01-01" & data_mod$date <= "2016-03-31","2016_Q1",
                                    ifelse(data_mod$date >= "2016-04-01" & data_mod$date <= "2016-06-30","2016_Q2",
                                           ifelse(data_mod$date >= "2016-07-01" & data_mod$date <= "2016-09-30","2016_Q3",
                                                  ifelse(data_mod$date >= "2016-10-01" & data_mod$date <= "2016-12-31","2016_Q4",
                                                         ifelse(data_mod$date >= "2017-01-01" & data_mod$date <= "2017-03-31","2017_Q1",
                                                                ifelse(data_mod$date >= "2017-04-01" & data_mod$date <= "2017-06-30","2017_Q2",
                                                                       ifelse(data_mod$date >= "2017-07-01" & data_mod$date <= "2017-09-30","2017_Q3",
                                                                              ifelse(data_mod$date >= "2017-10-01" & data_mod$date <= "2017-12-31","2017_Q4",
                                                                                     ifelse(data_mod$date >= "2018-01-01" & data_mod$date <= "2018-03-31","2018_Q1",
                                                                                            ifelse(data_mod$date >= "2018-04-01" & data_mod$date <= "2018-06-30","2018_Q2",
                                                                                                   ifelse(data_mod$date >= "2018-07-01" & data_mod$date <= "2018-09-30","2018_Q3",
                                                                                                          ifelse(data_mod$date >= "2018-10-01" & data_mod$date <= "2018-12-31","2018_Q4",
                                                                                                                 ifelse(data_mod$date >= "2019-01-01" & data_mod$date <= "2019-03-31","2019_Q1",
                                                                                                                        ifelse(data_mod$date >= "2019-04-01" & data_mod$date <= "2019-06-30","2019_Q2",
                                                                                                                               ifelse(data_mod$date >= "2019-07-01" & data_mod$date <= "2019-09-30","2019_Q3",
                                                                                                                                      ifelse(data_mod$date >= "2019-10-01" & data_mod$date <= "2019-12-31","2019_Q4",
                                                                                                                                             ifelse(data_mod$date >= "2020-01-01" & data_mod$date <= "2020-03-31","2020_Q1",
                                                                                                                                                    ifelse(data_mod$date >= "2020-04-01" & data_mod$date <= "2020-06-30","2020_Q2",
                                                                                                                                                           ifelse(data_mod$date >= "2020-07-01" & data_mod$date <= "2020-09-30","2020_Q3",
                                                                                                                                                                  ifelse(data_mod$date >= "2020-10-01" & data_mod$date <= "2020-12-31","2020_Q4",""
                                                                                                                                                                         )))))))))))))))))))))
quarter_price=data.frame(aggregate(data_mod$price, list(data_mod$quarter), FUN=mean))
ggplot(quarter_price, aes(x=factor(Group.1), y=x)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

```{r Factorization}
# Removing static/non-predictive columns
delcols = c('easement','aptnum','address','borough','resunits','comunits','totunits')
data_mod2 = subset(data_mod, select = -c(easement,aptnum,address,borough,resunits,comunits,totunits))

# Factorizing categorical variables
factcols = c('neighborhood','bldclasscat','taxclasscurr','block','lot','bldclasscurr','zip','yrbuilt','taxclasssale','bldclasssale','locality','quarter')
data_mod2[,factcols] = lapply(data_mod2[,factcols],factor)
str(data_mod2)
```

## 3.0 Initial Modelling - without transformations
```{r Naive_models}
naive.lm2 = lm(price~neighborhood+bldclasscat+taxclasscurr+bldclasscurr+landsqft+grosssqft+taxclasssale+bldclasssale+locality+quarter, data = data_mod2)
summary(naive.lm2)

naive.lm3 = lm(price~neighborhood+bldclasscat+taxclasscurr+bldclasscurr+(landsqft*grosssqft)+taxclasssale+bldclasssale+locality+quarter, data = data_mod2)
summary(naive.lm3)
```

## Continuing Initial Modelling - Analyzing Transformations
```{r Transform}

ggplot(data_mod2, aes(sqrt(grosssqft), sqrt(price))) + geom_line()
ggplot(data_mod2[data_mod2$grosssqft<5000,], aes(grosssqft, sqrt(price))) + geom_point()
ggplot(data_mod2, aes(landsqft, sqrt(price))) + geom_point()

ggplot(data_mod, aes(x=grosssqft)) + geom_histogram(bins = 100) + ggtitle("Spread of Grosssqft")
ggplot(data_mod, aes(x=log(grosssqft))) + geom_histogram(bins = 100) + ggtitle("Spread of Grosssqft")

ggplot(data_mod, aes(x=landsqft)) + geom_histogram(bins = 100) + ggtitle("Spread of Landsqft")
ggplot(data_mod[data_mod$landsqft>0,], aes(x=log(1+landsqft))) + geom_histogram(bins = 100) + ggtitle("Spread of Landsqft")

ggplot(data_mod, aes(x=price)) + geom_histogram(bins = 100) + ggtitle("Spread of Price")
ggplot(data_mod, aes(x=sqrt(price))) + geom_histogram(bins = 100) + ggtitle("Spread of Sqrt(Price)")
ggplot(data_mod[data_mod$price<10000000,], aes(x=sqrt(price))) + geom_histogram(bins = 100) + ggtitle("Spread of Price")

```

## 3.1 Continuing with feature engineering

```{r Cont_Feature_Engineering}
# For experimenting - trying year and quarter separately also
data_mod2$quartf = as.factor(substr(data_mod2$quarter,6,7))
data_mod2$yearsl = as.factor(substr(data_mod2$quarter,1,4))

# Adding neighbourhood levels with price
new_neigh_level10 = as.vector(neigh_price$Group.1[55:60])
new_neigh_level9 = as.vector(neigh_price$Group.1[49:54])
new_neigh_level8 = as.vector(neigh_price$Group.1[43:48])
new_neigh_level7 = as.vector(neigh_price$Group.1[37:42])
new_neigh_level6 = as.vector(neigh_price$Group.1[31:36])
new_neigh_level5 = as.vector(neigh_price$Group.1[25:30])
new_neigh_level4 = as.vector(neigh_price$Group.1[19:24])
new_neigh_level3 = as.vector(neigh_price$Group.1[13:18])
new_neigh_level2 = as.vector(neigh_price$Group.1[7:12])
new_neigh_level1 = as.vector(neigh_price$Group.1[1:6])

data_mod2$new_neigh_level = as.factor(ifelse(data_mod2$neighborhood %in% new_neigh_level1, 'new_neigh_level1',
                                         ifelse(data_mod2$neighborhood %in% new_neigh_level2, 'new_neigh_level2',
                                                ifelse(data_mod2$neighborhood %in% new_neigh_level3, 'new_neigh_level3',
                                                       ifelse(data_mod2$neighborhood %in% new_neigh_level4, 'new_neigh_level4',
                                                              ifelse(data_mod2$neighborhood %in% new_neigh_level5, 'new_neigh_level5',
                                                                     ifelse(data_mod2$neighborhood %in% new_neigh_level6, 'new_neigh_level6',
                                                                            ifelse(data_mod2$neighborhood %in% new_neigh_level7, 'new_neigh_level7',
                                                                                   ifelse(data_mod2$neighborhood %in% new_neigh_level8, 'new_neigh_level8',
                                                                                          ifelse(data_mod2$neighborhood %in% new_neigh_level9, 'new_neigh_level9',
                                                                                                 ifelse(data_mod2$neighborhood %in% new_neigh_level10, 'new_neigh_level10',"")))))))))))

```

## 3.2 Intermediate Models - Deprioritized
```{r Int_Models}

trans.lm6 = lm(I(sqrt(price))~new_neigh_level+bldclasscat+(landsqft*I(log(grosssqft)))+locality+yearsl+quartf, data = data_mod2)
summary(trans.lm6)
sqrt(sum(((trans.lm6$fitted.values)^2 - data_mod2$price)^2)/length(trans.lm6$fitted.values))

#TRANSFORMING LANDSQFT
trans.lm7 = lm(I(sqrt(price))~new_neigh_level+bldclasscat+I(log(1+landsqft))+I(log(grosssqft))+locality+yearsl+quartf, data = data_mod2)
summary(trans.lm7)
summary(log(1+data_mod2$landsqft))

data_mod3 = data_mod2[data_mod2$landsqft>10,]
trans.lm7new = lm(I(sqrt(price))~new_neigh_level+bldclasscat+(I(log(landsqft))*I(log(grosssqft)))+locality+yearsl+quartf, data = data_mod3)
summary(trans.lm7new)
cor(data_mod2$landsqft,data_mod2$grosssqft)

# LANDSQFT Works with a log(x) transformation for predicting sqrt(price), but this is significant only when landsqft>0
# That will reduce the rows to 11K, so not making that change
# Sticking to log(1+landsqft) only for now

# ADDING TAX and Building CLASSES TO THE MODEL
summary(lm(I(sqrt(price))~(bldclasscurr), data = data_mod2))

#Both Bldclasscurr and Bldclasssale explain close to 15% variance in sales prices, including one in the model
#Bucketing Bldclasssale as per mean prices to reduce model degree of freedom

bldcurr_price=data.frame(aggregate(sqrt(data_mod2$price), list(data_mod2$bldclasscurr), FUN=mean))
ggplot(bldcurr_price, aes(x=factor(Group.1), y=x)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

bldsale_price=data.frame(aggregate(sqrt(data_mod2$price), list(data_mod2$bldclasssale), FUN=mean))
ggplot(bldsale_price, aes(x=factor(Group.1), y=x)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

trans.lm8 = lm(I(sqrt(price))~new_neigh_level+bldclasscat+I(log(1+landsqft))+I(log(grosssqft))+locality+yearsl+quartf+bldclasssale, data = data_mod2)
summary(trans.lm8)

bld_sale_Alow = c('A0','A1','A2','A5','A6','A9')
bld_sale_Amed = c('A3','A4','A7')
bld_sale_Rlow = c('R1','R2','R3','R4','R5','R6','RR')
data_mod2$new_bld_sale = as.factor(ifelse(data_mod2$bldclasssale %in% bld_sale_Alow, 'bld_sale_Alow',
                                             ifelse(data_mod2$bldclasssale %in% bld_sale_Amed, 'bld_sale_Amed',
                                                    ifelse(data_mod2$bldclasssale %in% bld_sale_Rlow, 'bld_sale_Rlow',""))))

trans.lm9 = lm(I(sqrt(price))~new_neigh_level+bldclasscat+I(log(1+landsqft))+I(log(grosssqft))+locality+yearsl+quartf+new_bld_sale, data = data_mod2)
summary(trans.lm9)
calc.relimp(trans.lm9)
sqrt(sum(((trans.lm9$fitted.values)^2 - data_mod2$price)^2)/length(trans.lm9$fitted.values))

## No prediction power coming from tax sale category, not included in the model
summary(lm(I(sqrt(price))~(taxclasscurr*taxclasssale), data = data_mod2))

tax_sale_price=data.frame(aggregate(sqrt(data_mod2$price), list(data_mod2$taxclasssale), FUN=mean))
ggplot(tax_sale_price, aes(x=factor(Group.1), y=x)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
trans.lm10 = lm(I(sqrt(price))~new_neigh_level+bldclasscat+I(log(1+landsqft))+I(log(grosssqft))+locality+yearsl+quartf+new_bld_sale+taxclasssale, data = data_mod2)
summary(trans.lm10)

```

# 3.3 Final Model
```{r Fin_Model}
##  Reducing Modelling data to exclude price outliers
summary(data_mod2$price)
boxplot(data_mod2$price, data=data_mod2)
data_mod4 = data_mod2[data_mod2$price>=100000 & data_mod2$price<=7000000,]
dim(data_mod4)

trans.lm12 = lm(I(sqrt(price))~new_neigh_level+bldclasscat+I(log(1+landsqft))+I(log(grosssqft))+locality+quarter, data = data_mod4)
summary(trans.lm12)
sqrt(sum(((trans.lm12$fitted.values)^2 - data_mod4$price)^2)/length(trans.lm12$fitted.values))
calc.relimp(trans.lm12)
```